<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  
  
  <title>Parallel Processing &mdash; Monix</title>

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@monix" />  
  <meta name="twitter:image" content="https://monix.io/public/images/monix-logo-rect.png" />
  <meta name="twitter:title" content="Parallel Processing &mdash; Monix" />
  <meta name="twitter:description" content="Recipes for achieving parallelism" />

  <!-- Facebook Open-Graph -->
  <meta property="og:url" content="https://monix.io/docs/2x/tutorials/parallelism" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="Parallel Processing &mdash; Monix" />
  <meta property="og:description" content="Recipes for achieving parallelism" />
  <meta property="og:image" content="https://monix.io/public/images/monix-logo.png" />

  <!-- Google authorship -->
  <link href="https://aboutme.google.com/b/114636882626291639915/" rel="publisher">

  <!-- Javascript -->
  <script src="//code.jquery.com/jquery-2.2.4.min.js" type="text/javascript" language="javascript"></script>
  <script src="/public/js/toc.js" type="text/javascript" language="javascript"></script>
  <script src="/public/js/init.js" type="text/javascript" language="javascript"></script>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/all.css?1529908828232839300">
  <!--[if lt IE 9]>
  <link rel="stylesheet" href="/public/css/forkme.ie.css?1529908828232839300">
  <![endif]-->

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Web App Manifest, see: http://manifest.sysapps.org/ -->
  <link rel="manifest" href="/manifest.json">
  <!-- Icons -->
  <link rel="icon" sizes="48x48" href="/public/icons/icon-48x48.png">
  <link rel="icon" sizes="72x72" href="/public/icons/icon-72x72.png">
  <link rel="icon" sizes="96x96" href="/public/icons/icon-96x96.png">
  <link rel="icon" sizes="144x144" href="/public/icons/icon-144x144.png">
  <link rel="icon" sizes="192x192" href="/public/icons/icon-192x192.png">
  <link rel="icon" sizes="240x240" href="/public/icons/icon-240x240.png">
  <link rel="icon" sizes="384x384" href="/public/icons/icon-384x384.png">
  <!-- Mobile Safari / iOS Icons -->
  <link rel="apple-touch-icon" sizes="48x48" href="/public/icons/icon-48x48.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/public/icons/icon-72x72.png">
  <link rel="apple-touch-icon" sizes="96x96" href="/public/icons/icon-96x96.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/public/icons/icon-144x144.png">
  <link rel="apple-touch-icon" sizes="192x192" href="/public/icons/icon-192x192.png">
  <link rel="apple-touch-icon" sizes="240x240" href="/public/icons/icon-240x240.png">
  <link rel="apple-touch-icon" sizes="384x384" href="/public/icons/icon-384x384.png">
  <!-- Standard Favicon -->
  <link rel="shortcut icon" href="/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/atom+xml" title="Feed" href="/blog/atom.xml">
</head>


  <body class="monix layout">
    <div class="wrapper">
      <aside class="sidebar plus">
  <div class="container">
    <div class="sidebar-about">
      <a class="github-fork-ribbon left-top" href="https://github.com/monix/monix"
        title="Fork me on GitHub">Fork me on GitHub</a>

      <h1>
        <a href="/">
          <img src="/public/images/monix-logo.png"
            alt="Monix Logo" title="Monix" class="logo" />
        </a>
      </h1>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">About</a>
      <a class="sidebar-nav-item" href="/blog/">Blog</a>
      <a class="sidebar-nav-item active" href="/docs/3x/">Documentation</a>
      <a class="sidebar-nav-item" href="/presentations/">Presentations</a>
      <a class="sidebar-nav-item" href="https://github.com/monix/monix">GitHub project</a>
      <a class="sidebar-nav-item" href="/social.html">Follow @Monix</a>
    </nav>
  </div>
</aside>

    
      <article class="content container">
        <div class="page">
  <h1 class="page-title">Parallel Processing</h1>

  <nav role="navigation" id="type-info">
    
    
    
    <a href="https://github.com/monix/monix.io/edit/master/_tut/docs/2x/tutorials/parallelism.md">Edit Page</a>
  </nav>
  
  <div id="version2x">
    You are viewing the documentation for the older Monix 2.x series.<br />
    If you're looking for the latest 3.x
    <a href="/docs/3x/">click here</a>!
  </div>

  <nav role="navigation" id="toc"></nav>

  <p>Monix provides multiple ways for achieving parallelism, depending on use-case.</p>

<p>The samples in this document are copy/paste-able, but to get the imports out of the way:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// On evaluation a Scheduler is needed
</span><span class="k">import</span> <span class="nn">monix.execution.Scheduler.Implicits.global</span>
<span class="c1">// For Task
</span><span class="k">import</span> <span class="nn">monix.eval._</span>
<span class="c1">// For Observable
</span><span class="k">import</span> <span class="nn">monix.reactive._</span>
</code></pre></div></div>

<h2 id="parallelism-with-task">Parallelism with Task</h2>

<p>We can do parallel execution in batches, that does deterministic
(ordered) signaling of results with the help of <a href="../eval/task.html">Task</a>.</p>

<h3 id="the-naive-way">The Naive Way</h3>

<p>The following example uses
<a href="/api/2.3/monix/eval/Task$.html#gather[A,M[X]&lt;:TraversableOnce[X]](in:M[monix.eval.Task[A]])(implicitcbf:scala.collection.generic.CanBuildFrom[M[monix.eval.Task[A]],A,M[A]]):monix.eval.Task[M[A]]">Task.gather</a>,
which does parallel processing while preserving result ordering, 
but in order to ensure that parallel processing actually happens,
the tasks need to be effectively asynchronous, which for simple
functions need to fork threads, hence the usage of 
<a href="/api/2.3/monix/eval/Task$.html#apply[A](f:=&gt;A):monix.eval.Task[A]">Task.apply</a>,
although remember that you can apply 
<a href="/api/2.3/monix/eval/Task$.html#fork[A](fa:monix.eval.Task[A]):monix.eval.Task[A]">Task.fork</a>
to any task.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">items</span> <span class="k">=</span> <span class="mi">0</span> <span class="n">until</span> <span class="mi">1000</span>

<span class="c1">// The list of all tasks needed for execution
</span><span class="k">val</span> <span class="n">tasks</span> <span class="k">=</span> <span class="n">items</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="nc">Task</span><span class="o">(</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="o">))</span>
<span class="c1">// Processing in parallel
</span><span class="k">val</span> <span class="n">aggregate</span> <span class="k">=</span> <span class="nc">Task</span><span class="o">.</span><span class="n">gather</span><span class="o">(</span><span class="n">tasks</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toList</span><span class="o">)</span>

<span class="c1">// Evaluation:
</span><span class="n">aggregate</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
<span class="c1">//=&gt; List(0, 2, 4, 6, 8, 10, 12, 14, 16,...
</span></code></pre></div></div>

<p>If ordering of results does not matter, you can also use 
<a href="/api/2.3/monix/eval/Task$.html#gatherUnordered[A](in:TraversableOnce[monix.eval.Task[A]]):monix.eval.Task[List[A]]">Task.gatherUnordered</a>
instead of <code class="highlighter-rouge">gather</code>, which might yield better results, given its non-blocking execution.</p>

<h3 id="imposing-a-parallelism-limit">Imposing a Parallelism Limit</h3>

<p>The <code class="highlighter-rouge">Task.gather</code> builder, as exemplified above, will potentially execute
all given tasks in parallel, the problem being that this can lead to inefficiency.
For example we might be doing HTTP requests and starting 10000 HTTP
requests in parallel is not necessarily wise as it can choke the
server on the other end.</p>

<p>To solve this we can split the workload in batches of parallel tasks that
are then sequenced:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">items</span> <span class="k">=</span> <span class="mi">0</span> <span class="n">until</span> <span class="mi">1000</span>
<span class="c1">// The list of all tasks needed for execution
</span><span class="k">val</span> <span class="n">tasks</span> <span class="k">=</span> <span class="n">items</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="nc">Task</span><span class="o">(</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="o">))</span>
<span class="c1">// Building batches of 10 tasks to execute in parallel:
</span><span class="k">val</span> <span class="n">batches</span> <span class="k">=</span> <span class="n">tasks</span><span class="o">.</span><span class="n">sliding</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span><span class="mi">10</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">b</span> <span class="k">=&gt;</span> <span class="nc">Task</span><span class="o">.</span><span class="n">gather</span><span class="o">(</span><span class="n">b</span><span class="o">))</span>
<span class="c1">// Sequencing batches, then flattening the final result
</span><span class="k">val</span> <span class="n">aggregate</span> <span class="k">=</span> <span class="nc">Task</span><span class="o">.</span><span class="n">sequence</span><span class="o">(</span><span class="n">batches</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">flatten</span><span class="o">.</span><span class="n">toList</span><span class="o">)</span>

<span class="c1">// Evaluation:
</span><span class="n">aggregate</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
<span class="c1">//=&gt; List(0, 2, 4, 6, 8, 10, 12, 14, 16,...
</span></code></pre></div></div>

<p>Note how this strategy is difficult to achieve with Scala’s <code class="highlighter-rouge">Future</code>
because even though we have <code class="highlighter-rouge">Future.sequence</code>, its behavior is strict
and is thus not able to differentiate well between sequencing and
parallelism, this behavior being controlled by passing a lazy or a
strict sequence to <code class="highlighter-rouge">Future.sequence</code>, which is obviously error-prone.</p>

<h3 id="batched-observables">Batched Observables</h3>

<p>We can also combine this with <code class="highlighter-rouge">Observable.flatMap</code> for doing requests
in batches:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">monix.eval._</span>
<span class="k">import</span> <span class="nn">monix.reactive._</span>

<span class="c1">// The `bufferIntrospective` will do buffering, up to a certain
// `bufferSize`, for as long as the downstream is busy and then
// stream a whole sequence of all buffered events at once
</span><span class="k">val</span> <span class="n">source</span> <span class="k">=</span> <span class="nc">Observable</span><span class="o">.</span><span class="n">range</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1000</span><span class="o">).</span><span class="n">bufferIntrospective</span><span class="o">(</span><span class="mi">256</span><span class="o">)</span>

<span class="c1">// Processing in batches, powered by `Task`
</span><span class="k">val</span> <span class="n">batched</span> <span class="k">=</span> <span class="n">source</span><span class="o">.</span><span class="n">flatMap</span> <span class="o">{</span> <span class="n">items</span> <span class="k">=&gt;</span>
  <span class="c1">// The list of all tasks needed for execution
</span>  <span class="k">val</span> <span class="n">tasks</span> <span class="k">=</span> <span class="n">items</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="nc">Task</span><span class="o">(</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="o">))</span>
  <span class="c1">// Building batches of 10 tasks to execute in parallel:
</span>  <span class="k">val</span> <span class="n">batches</span> <span class="k">=</span> <span class="n">tasks</span><span class="o">.</span><span class="n">sliding</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span><span class="mi">10</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">b</span> <span class="k">=&gt;</span> <span class="nc">Task</span><span class="o">.</span><span class="n">gather</span><span class="o">(</span><span class="n">b</span><span class="o">))</span>
  <span class="c1">// Sequencing batches, then flattening the final result
</span>  <span class="k">val</span> <span class="n">aggregate</span> <span class="k">=</span> <span class="nc">Task</span><span class="o">.</span><span class="n">sequence</span><span class="o">(</span><span class="n">batches</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">flatten</span><span class="o">)</span>
  <span class="c1">// Converting into an observable, needed for flatMap
</span>  <span class="nc">Observable</span><span class="o">.</span><span class="n">fromTask</span><span class="o">(</span><span class="n">aggregate</span><span class="o">)</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="nc">Observable</span><span class="o">.</span><span class="n">fromIterator</span><span class="o">(</span><span class="n">i</span><span class="o">))</span>
<span class="o">}</span>

<span class="c1">// Evaluation:
</span><span class="n">batched</span><span class="o">.</span><span class="n">toListL</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
<span class="c1">//=&gt; List(0, 2, 4, 6, 8, 10, 12, 14, 16,...
</span></code></pre></div></div>

<p>Note the use of 
<a href="/api/2.3/monix/reactive/Observable.html#bufferIntrospective(maxSize:Int):Self[List[A]]">bufferIntrospective</a>,
which buffers incoming events while the downstream is busy, after which
it emits the buffer as a single bundle. The
<a href="/api/2.3/monix/reactive/Observable.html#bufferTumbling(count:Int):Self[Seq[A]]">bufferTumbling</a>
operator can be a more deterministic alternative.</p>

<h2 id="observablemapasync">Observable.mapAsync</h2>

<p>Another way to achieve parallelism is to use the 
<a href="/api/2.3/monix/reactive/Observable.html#mapAsync[B](parallelism:Int)(f:A=&gt;monix.eval.Task[B]):Self[B]">Observable.mapAsync</a>
operator:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">source</span> <span class="k">=</span> <span class="nc">Observable</span><span class="o">.</span><span class="n">range</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1000</span><span class="o">)</span>
<span class="c1">// The parallelism factor needs to be specified
</span><span class="k">val</span> <span class="n">processed</span> <span class="k">=</span> <span class="n">source</span><span class="o">.</span><span class="n">mapAsync</span><span class="o">(</span><span class="n">parallelism</span> <span class="k">=</span> <span class="mi">10</span><span class="o">)</span> <span class="o">{</span> <span class="n">i</span> <span class="k">=&gt;</span>
  <span class="nc">Task</span><span class="o">(</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="o">)</span>
<span class="o">}</span>

<span class="c1">// Evaluation:
</span><span class="n">processed</span><span class="o">.</span><span class="n">toListL</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
<span class="c1">//=&gt; List(2, 10, 0, 4, 8, 6, 12...
</span></code></pre></div></div>

<p>Compared with using <code class="highlighter-rouge">Task.gather</code> as exemplified above, this operator
<strong>does not maintain ordering</strong> of results as signaled by the source.</p>

<p>This leads to a more efficient execution, because the source doesn’t
get back-pressured for as long as there’s at least one worker active,
whereas with the batched execution strategy exemplified above we can
have inefficiencies due to a single async task that takes too long to
complete.</p>

<h2 id="observablemergemap">Observable.mergeMap</h2>

<p>If <code class="highlighter-rouge">Observable.mapAsync</code> works with <code class="highlighter-rouge">Task</code>, then 
<a href="https://monix.io/api/2.2/monix/reactive/Observable.html#mergeMap[B](f:A=%3Emonix.reactive.Observable[B])(implicitos:monix.reactive.OverflowStrategy[B]):Self[B]">Observable.mergeMap</a>
works by merging <code class="highlighter-rouge">Observable</code> instances.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">source</span> <span class="k">=</span> <span class="nc">Observable</span><span class="o">.</span><span class="n">range</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1000</span><span class="o">)</span>
<span class="c1">// The parallelism factor needs to be specified
</span><span class="k">val</span> <span class="n">processed</span> <span class="k">=</span> <span class="n">source</span><span class="o">.</span><span class="n">mergeMap</span> <span class="o">{</span> <span class="n">i</span> <span class="k">=&gt;</span>
  <span class="nc">Observable</span><span class="o">.</span><span class="n">fork</span><span class="o">(</span><span class="nc">Observable</span><span class="o">.</span><span class="n">eval</span><span class="o">(</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="o">))</span>
<span class="o">}</span>

<span class="c1">// Evaluation:
</span><span class="n">processed</span><span class="o">.</span><span class="n">toListL</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
<span class="c1">//=&gt; List(0, 4, 6, 2, 8, 10, 12, 14...
</span></code></pre></div></div>

<p>Note that <code class="highlighter-rouge">mergeMap</code> is similar with <code class="highlighter-rouge">concatMap</code> (aliased by <code class="highlighter-rouge">flatMap</code>
in Monix), except that the observable streams emitted by the source
get subscribed in parallel and thus the result is non-deterministic.</p>

<p>Note that this <code class="highlighter-rouge">mergeMap</code> call, as exemplified above, does not have an
optional <code class="highlighter-rouge">parallelism</code> parameter, which means that if the source is
chatty, we can end up with <em>a lot</em> of observables subscribed in
parallel. The issue is that the <code class="highlighter-rouge">mergeMap</code> operator is not meant for
actual processing in parallel, but for joining active, concurrent
streams.</p>

<h2 id="consumerloadbalancer">Consumer.loadBalancer</h2>

<p>We can apply a <code class="highlighter-rouge">mapAsync</code> like operation on the consumer side, as
exemplified in the <a href="../reactive/consumer.html">Consumer</a> tutorial, by means of a
load-balanced consumer, being able to do a final aggregate of the
results of all workers:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">monix.eval._</span>
<span class="k">import</span> <span class="nn">monix.reactive._</span>

<span class="c1">// A consumer that folds over the elements of the stream,
// producing a sum as a result
</span><span class="k">val</span> <span class="n">sumConsumer</span> <span class="k">=</span> <span class="nc">Consumer</span><span class="o">.</span><span class="n">foldLeft</span><span class="o">[</span><span class="kt">Long</span>,<span class="kt">Long</span><span class="o">](</span><span class="mi">0L</span><span class="o">)(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">)</span>

<span class="c1">// For processing sums in parallel, useless of course, but can become 
// really helpful for logic sprinkled with I/O bound stuff
</span><span class="k">val</span> <span class="n">loadBalancer</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nc">Consumer</span>
    <span class="o">.</span><span class="n">loadBalance</span><span class="o">(</span><span class="n">parallelism</span><span class="k">=</span><span class="mi">10</span><span class="o">,</span> <span class="n">sumConsumer</span><span class="o">)</span>
    <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">sum</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">observable</span><span class="k">:</span> <span class="kt">Observable</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Observable</span><span class="o">.</span><span class="n">range</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">100000</span><span class="o">)</span>
<span class="c1">// Our consumer turns our observable into a Task processing sums, w00t!
</span><span class="k">val</span> <span class="n">task</span><span class="k">:</span> <span class="kt">Task</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="n">observable</span><span class="o">.</span><span class="n">consumeWith</span><span class="o">(</span><span class="n">loadBalancer</span><span class="o">)</span>

<span class="c1">// Consume the whole stream and get the result
</span><span class="n">task</span><span class="o">.</span><span class="n">runAsync</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
<span class="c1">//=&gt; 4999950000
</span></code></pre></div></div>

<p>Read the <a href="../reactive/consumer.html">Consumer</a> document for more details.</p>


  <div class="buttons">
    <a href="/docs/2x/">Contents</a> •
    <a href="https://github.com/monix/monix.io/edit/master/_tut/docs/2x/tutorials/parallelism.md">
      Edit Page</a> •
    
    <a href="https://gitter.im/monix/monix">
      Join Chat</a> •
    <a href="/social.html">
      Follow</a>
  </div>
</div>

      </article>    
    </div>

    <script>
        ((window.gitter = {}).chat = {}).options = {
          room: 'monix/monix'
        };
    </script>
    <script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>
  </body>
</html>
